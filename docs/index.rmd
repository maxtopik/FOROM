---
title: "R Markdown Report"
author: "Max TÃ¶lle"
output:
  html_document: default
  pdf_document: default
---

# Script and data overview for Jinggang et al. 2024

In this Script, the processing of NPP data and of FOROM output data is compiled

## NPP data

NPP model outputs were collected by Jinfeng Chang (College of Environmental and Resource Sciences, Zhejiang University, Hangzhou, China) and are currently stored at <https://www.pik-potsdam.de/~reyer/ISIMIP2b_forest_csv_2022-11-25/>.

The data were processed as followed:

Necessary libraries:

```{r message=FALSE, warning=FALSE}

rm(list = ls())
options(scipen = 999)

library(ncdf4)
library(terra)
library(itsadug)
library("RColorBrewer")
library(reshape2)
library(tidyverse); library(fs); library(readxl)
library("scales")
library(ggplot2)
library(plyr)
library(dplyr)
library(purrr)
library(forestmangr)
library(ggpubr)
library(tidyterra)
library(zoo)
```

Files and Script preparation:

```{r message=FALSE, warning=FALSE}
FOROM_regions <- read.table("C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/FOROM_regions.txt", fill = TRUE) #names of the 50 regions
```

**1.) data import**

import NPP data for the GVMs CARAIB, LPJ-GUESS, LPJmL, ORCHIDEE

```{r message=FALSE, warning=FALSE}
excel_files <- dir_ls(path =  "C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/NPP_new", regexp = "*.csv") #create listing (fs_path object) of relevant files to read

excel_files <- excel_files %>% #read all files and store their name in `source` variable
  set_names() %>% 
  map_dfr(read_csv, .id = "source")

excel_files$source <- as.character(excel_files$source) 

excel_files <- excel_files %>% #remove extension of the file name and separate into columns
  mutate(source = str_remove(source, "(.*)ISIMIP2b_")) %>% 
  separate(source, into = c("variable","forest", "vegmodel", "GCM", "rcp" ), sep = "_") %>% 
  subset(select = -c(forest,variable))
  
excel_files <- excel_files %>% 
  mutate(rcp = str_remove(rcp, ".csv")) 

names(excel_files)[4] <- "year"

excel_files <- excel_files %>% 
  mutate(year = ifelse(rcp == "historical", year + 1860, year)) %>% 
  mutate(year = ifelse(rcp %in% c("rcp26", "rcp60", "rcp85"), year + 2005, year))

names(excel_files)[5:54] <- c(FOROM_regions$V2)

excel_files[excel_files == 0] <- NA
```

import NPP data for the GVM MC2

```{r message = FALSE, warning=FALSE}
npp_files <- dir_ls(path = "C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/MC2", regexp = "*.csv") 

npp_files <- npp_files %>% 
  map_dfr(read_csv, .id = "source", skip = 1)

npp_files$source <- as.character(npp_files$source)

npp_files<- npp_files %>% 
  mutate(source = str_remove(source, "(.*)MC2/")) %>% 
  separate(source, into = c( "GCM", "rcp", "variable"), sep = "_") %>% 
  subset(select = -c(variable))
  
npp_files <- npp_files[-54]

names(npp_files)[4:53] <- c(FOROM_regions$V2)

npp_files$vegmodel <- c("MC2")

npp_files <- npp_files %>% 
  relocate(vegmodel)

npp_files <- npp_files %>% 
  mutate(rcp = ifelse(year <= 2005, "historical", rcp))
  

npp_files$NA_ROC <- NA #no data for NA_ROC is available for MC2
```

merge NPP data of vegetation models

```{r}
npp.data <- rbind(npp_files, excel_files) 
```

**2.) data prepatarion**

Subset the data to GVMs RCPs and time that is used

```{r}

npp.data <- subset(npp.data, npp.data$vegmodel != "CLM45") # CLM45 is not used in this study! 

npp.data <- subset(npp.data, npp.data$year %in% c(1964:2099)) # subset to time of concern

npp.data <-npp.data %>%
  filter(!(GCM=="gfdl-esm2m" & vegmodel== "CARAIB" & rcp =="rcp85" )) %>%
  filter(!(GCM=="hadgem2-es" & vegmodel== "CARAIB"& rcp =="rcp85" )) %>%
  filter(!(GCM=="ipsl-cm5a-lr" & vegmodel== "CARAIB" & rcp =="rcp85")) %>%
  filter(!(GCM=="miroc5" & vegmodel== "CARAIB"& rcp =="rcp85" )) 
  
  
```

overview of NPP data:

```{r}
head(npp.data, 10)
```

transform data from wide to long:

```{r}
npp.data <- melt(npp.data, id.vars = c("vegmodel", "GCM", "rcp", "year"))

colnames(npp.data)[colnames(npp.data) == "variable"] <- "region"

str(npp.data)

```

**3.) mean calculation**

5-year rolling averages for NPP data

```{r}
rolling_avg_window <- 5 # take the last 5 years for the calculation of mean 

npp.data <- npp.data %>%
  group_by(vegmodel,GCM,rcp,region) %>%
  mutate(RollingAverage = rollmean(value, k = rolling_avg_window, align = "right", fill = NA))
```

Calculate the average RollingAverage between 1980-2005 for each RCP and Region

```{r}
avg_rolling_1980_2005 <- npp.data %>%
  filter(year >= 1980 & year <= 2005) %>%
  group_by(vegmodel,GCM,rcp,region) %>%
  summarize(avg_rolling_1980_2005 = mean(RollingAverage, na.rm = TRUE)) %>% 
  subset(select = -c(rcp))

```

Join the average RollingAverage of the baseline period back to the original dataframe

```{r}
npp.data <- npp.data %>%
  left_join(avg_rolling_1980_2005, by = c("vegmodel","GCM","region"))
```

Calculate the percentage increase/decrease of the actual rolling average in NPP compared to the baseline period

```{r}
npp.data$Percentage <- (npp.data$value - npp.data$avg_rolling_1980_2005) / npp.data$avg_rolling_1980_2005


dt <- npp.data %>% 
  filter(year==2020|year==2025|year==2030|year==2035|year==2040|year==2045|year==2050|year==2055|year==2060|year==2065|year==2070)%>%
  select(vegmodel, GCM,rcp, region,year,value,avg_rolling_1980_2005,Percentage) 
```

This dataset "dt" is used for the simulation in the FOROM model with only minor adjustments. After the model was run, the output is again processed in R!

**FOROM data**

GAMS need to be installed on your computer in order to convert the .gdx-file in a readable R table. You can download it here: <https://www.gams.com/download/>

Loading necessary packages:

```{r message=FALSE, warning=FALSE}
library(scales)
library(readr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(zoo)
library(tidyr)
library(sf)
library(viridis)
library(ggtext)
library(data.table)
# install.packages('gdxrrw')
# # if this is not
# working try
# install_github('GAMS-dev/gdxrrw/gdxrrw')
library(gdxrrw)
library(reshape2)
```

set igdx to local file of GAMS

```{r message = FALSE}
igdx("C:/GAMS/46")

```

**PS_all (Price)**

1.) Import dataset

```{r message=FALSE, warning=FALSE}
price_df <- data.table(rgdx.param("C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/merged.gdx","PS_ALL"))
colnames(price_df) <- c("SSP","Scenario", "Product","Region", "Year","Value")
price_df$Scenario <- as.character(price_df$Scenario)
price_df$Scenario <- ifelse(grepl("^[[:lower:]a-z]",price_df$Scenario),paste0("MC2_",price_df$Scenario),price_df$Scenario)
```

2.) filter the dataframe!

```{r message = FALSE, warning = FALSE}
price_df <- price_df %>%
  filter(Year %in% c("2020","2050", "2070"))  %>%
  separate(Scenario, into = c("DGVM", "GCM", "RCP"), sep = "_") #%>%
  #filter(GCM !="baseline") #eventually this needs to be dropped
  #filter(Region =="WORLD")

```

3.) take the mean over GCMs and calculate the percentage change

```{r}
##Summarize for mean and SD over GCMs 
percentage_changes_price <- price_df %>%
group_by(SSP, Product,Region, Year,DGVM, RCP) %>%
summarize(AverageValue = mean(Value,na.rm = TRUE), 
          SD_Value = sd(Value, na.rm = TRUE),.groups = "drop")

#transform data set 
percentage_changes_price <- percentage_changes_price %>%
  filter(Year %in% c("2020", "2070")) %>%
  pivot_wider(id_cols = c("SSP", "Product", "Region", "DGVM","RCP"),
              names_from = Year,
              values_from = c(AverageValue, SD_Value))

#calculate percentage
percentage_changes_price$percentage <- (percentage_changes_price$AverageValue_2070-percentage_changes_price$AverageValue_2020)/percentage_changes_price$AverageValue_2020*100


```

**QS_all (Quantity)**

1.) Import dataset

```{r}
quantity_df <- data.table(rgdx.param("C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/merged.gdx","QS_ALL"))
colnames(quantity_df) <- c("SSP","Scenario", "Product","Region", "Year","Value")
quantity_df$Scenario <- as.character(quantity_df$Scenario)
quantity_df$Scenario <- ifelse(grepl("^[[:lower:]a-z]",quantity_df$Scenario),paste0("MC2_",quantity_df$Scenario),quantity_df$Scenario)
```

2.) filter the dataframe!

```{r warning=FALSE}
quantity_df <- quantity_df %>%
  filter(Year %in% c("2020", "2050","2070"))  %>%
  separate(Scenario, into = c("DGVM", "GCM", "RCP"), sep = "_") #%>%
  #filter(GCM !="baseline") #%>%
  #filter(Region =="WORLD")

```

3.) take the mean over the GCMs and calculate the percentage change

```{r}
percentage_changes_quantity <- quantity_df %>%
group_by(SSP, Product,Region, Year,DGVM, RCP) %>%
summarize(AverageValue = mean(Value,na.rm = TRUE), 
          SD_Value = sd(Value, na.rm = TRUE),.groups = "drop")

percentage_changes_quantity <- percentage_changes_quantity %>%
  filter(Year %in% c("2020", "2070")) %>%
  pivot_wider(id_cols = c("SSP", "Product", "Region", "DGVM","RCP"),
              names_from = Year,
              values_from = c(AverageValue, SD_Value))

#calculate percentage
percentage_changes_quantity$percentage2070 <- (percentage_changes_quantity$AverageValue_2070-percentage_changes_quantity$AverageValue_2020)/percentage_changes_quantity$AverageValue_2020*100


```

*Question1: Where are unrealisitc high/low values that need to be excluded??*

**Merge the data by continent!**

```{r}
region_to_rcode <- c(
  "Australia" = "Oceania",
  "Rest of Oceania" = "Oceania",
  "Chile" = "South America",
  "China" = "Asia",
  "France" = "Europe",
  "India" = "Asia",
  "Japan" = "Asia",
  "Russian Federation" = "Asia",
  "Rest of Africa" = "Africa",
  "Rest of Europe" = "Europe",
  "Rest of North America" = "North America",
  "Mexico" = "North America",
  "Pacific Coast" = "North America",
  "North Central" = "North America",
  "South Central" = "North America",
  "Argentina" = "South America",
  "Belarus" = "Europe",
  "Estonia" = "Europe",
  "Malaysia" = "Asia",
  "Nigeria" = "Africa",
  "Portugal" = "Europe",
  "Slovakia" = "Europe",
  "Spain" = "Europe",
  "Turkey" = "Asia",
  "United Kingdom" = "Europe",
  "Viet Nam" = "Asia",
  "New Zealand" = "Oceania",
  "Brazil" = "South America",
  "Rest of South America" = "South America",
  "Finland" = "Europe",
  "Germany" = "Europe",
  "Indonesia" = "Asia",
  "Poland" = "Europe",
  "Sweden" = "Europe",
  "Rest of Asia" = "Asia",
  "Rest of Central America" = "Central America",
  "Canada" = "North America",
  # "United States" = "North America",
  "Rocky Mountain" = "North America",
  "North East" = "North America",
  "South East" = "North America",
  "Austria" = "Europe",
  "Belgium" = "Europe",
  "Latvia" = "Europe",
  "Myanmar" = "Asia",
  "Norway" = "Europe",
  "Romania" = "Europe",
  "South Africa" = "Africa",
  "Thailand" = "Asia",
  "Ukraine" = "Europe",
  "Uruguay" = "South America"
)


  percentage_changes_price$continent <- region_to_rcode[as.character(percentage_changes_price$Region)]
  percentage_changes_quantity$continent <- region_to_rcode[as.character(percentage_changes_quantity$Region)]

```

Mean Values by Continent! *Question 2: Do we take the mean of the percentage changes or calculate the sum of NPP for the continent in 2020 and 2070 and calculate the percentage from there?*

```{r}
continent_price <- percentage_changes_price %>% 
  group_by(SSP, Product,DGVM,RCP, continent) %>% 
  summarize(sum2020 = sum(AverageValue_2020, na.rm = TRUE),
            sum2070 = sum(AverageValue_2070, na.rm = TRUE))

continent_price$percentage <- (continent_price$sum2070 - continent_price$sum2020) / continent_price$sum2020 * 100
```

```{r}
continent_quantity <- percentage_changes_quantity %>% 
  group_by(SSP, Product,DGVM,RCP, continent) %>% 
  summarize(sum2020 = sum(AverageValue_2020, na.rm = TRUE),
            sum2070 = sum(AverageValue_2070, na.rm = TRUE))

continent_quantity$percentage <- (continent_quantity$sum2070 - continent_quantity$sum2020) / continent_quantity$sum2020 * 100
```

Create Figure 1!

```{r}
combined_data <- left_join(price_df, quantity_df, by = c("SSP","Product", "Region", "Year", "DGVM", "RCP", "GCM")) %>%
  rename(Price = Value.x, Quantity = Value.y) 

combined_data$continent <- region_to_rcode[as.character(combined_data$Region)]

baseline_plot <- subset(combined_data, GCM == "baseline" & Year %in% c("2020","2070") & Product %in% c("IRC", "IRNC", "SWC", "SWNC") & Region %in% c("Europe", "Asia", "Africa", "Oceania", "South America", "North America", "Central America", "WORLD"))

data_plot <- subset(combined_data, GCM != "baseline" & Year == "2070" & Product %in% c("IRC", "IRNC", "SWC", "SWNC") & Region %in% c("Europe", "Asia", "Africa", "Oceania", "South America", "North America", "Central America", "WORLD"))

data_plot <- left_join(data_plot , baseline_plot %>% select(SSP,Product, Region, Year,Price, Quantity) %>% filter(Year == 2070), by = c("SSP", "Region", "Year", "Product")) %>% rename(Price = Price.x, Price_baseline = Price.y, Quantity = Quantity.x, Quantity_baseline = Quantity.y)

data_plot$Quantity_prct <- (data_plot$Quantity - data_plot$Quantity_baseline) / data_plot$Quantity_baseline * 100
data_plot$Price_prct <- (data_plot$Price - data_plot$Price_baseline) / data_plot$Price_baseline * 100

#data_plot <- data_plot %>% 
#  group_by(SSP, Region,RCP, Product) %>% 
#  summarise(mean_quantity = mean(Quantity, na.rm = TRUE), 
#            SD_quantity = sd(Quantity, na.rm = TRUE),
#            mean_quantity_prct = mean(Quantity_prct, na.rm = TRUE), 
#            SD_quantity_prct = sd(Quantity_prct, na.rm = TRUE),
#            mean_Price = mean(Price, na.rm = TRUE), 
#            SD_Price = sd(Price, na.rm = TRUE),
#            mean_Price_prct = mean(Price_prct, na.rm = TRUE),
#            SD_Price_prct = sd(Price_prct, na.rm = TRUE))

#data_plot$coniferous <- ifelse(grepl("N",data_plot$Product), "NO", "YES")

#data_plot <- data_plot %>% 
#  mutate(ID = row_number()) 


```

**Forest_Stock**

Import and rearrange data

```{r}
stock <- data.table(rgdx.param("C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/merged.gdx","Forstock1"))
colnames(stock) <- c("SSP","Scenario","Region", "Year","Value")
stock$Scenario <- as.character(stock$Scenario)
stock <- stock %>%
  filter(Year %in% c("2020", "2050" ,"2070"))  %>%
  separate(Scenario, into = c("DGVM", "GCM", "RCP"), sep = "_") #%>%

```

Smmarize data

```{r}
stock$continent <- region_to_rcode[as.character(stock$Region)]

stock <- stock %>% 
  group_by(SSP, DGVM, GCM, RCP, continent, Year) %>% 
  summarize(Sum = sum(Value, na.rm = TRUE))

stock <- stock %>% 
  pivot_wider(id_cols = c("SSP", "continent", "DGVM", "GCM", "RCP"),
              names_from = Year,
              values_from = Sum)

stock$percentage_2050 <- (stock$'2050' - stock$'2020') / stock$'2020' * 100
stock$percentage_2070 <- (stock$'2070' - stock$'2020') / stock$'2020' * 100


```

Question: Different values calculated than shown in Figure 2!!

**Relative Quantity Variation by GDP**

```{r}
GDP <- read.csv("C:/Users/maxto/Desktop/Hiwi-Arbeit/FOROM_paper/data/GDPP_Rate.csv")

#subset to 2050 
GDP <- GDP %>% 
  filter(Year == 2050) %>% 
  select(SSP, Region, Year, GDPP, Growth_rate) %>% 
  mutate(Year = as.character(Year))

#combine this dataset with relative quantity variation


baseline_quantity_variation <- subset(combined_data, GCM == "baseline" & Year == "2070" & Product == "IRC" & Region != "Rest of North America")

combined_data <- na.omit(combined_data)
#summary(combined_data)
combined_data <- combined_data %>% 
  filter(Year == "2050") %>% 
  mutate(Year = as.character(Year))

combined_data <- left_join(combined_data , GDP %>% select(SSP, Region, Year, GDPP, Growth_rate), by = c("SSP", "Region", "Year"))

combined_data <- combined_data %>% 
  filter(Product == "IRC") 

try <- left_join(combined_data, baseline_quantity_variation %>% select(-c(DGVM,GCM,RCP, continent)), by = c("SSP","Product", "Region", "Year")) %>% 
  rename(Quantity=Quantity.x, Price=Price.x , Quantity_baseline=Quantity.y, Price_baseline=Price.y)

try <- try %>% 
  group_by(SSP, Region, GDPP, Growth_rate, continent) %>% 
  summarize(PriceDifference = max(Quantity) - min(Quantity),
            PriceDifference_pct = 100* PriceDifference /mean(Quantity_baseline),
            .groups = 'drop')
  
```

##Random Forest Analysis

```{r}
# library(randomForest)
# library(datasets)
# library(caret)
# library(gbm)
# 
# set.seed(222)
# 
# ind <- sample(2, nrow(data), replace = TRUE, prob = c(0.7, 0.3))
# train <- data[ind==1,]
# test <- data[ind==2,]
# 
# 
# ## Random forest analysis
# rf <- randomForest(forest_stock~., data=train, proximity=TRUE)
# 
# 
# 
# ## Gradient Boosting model
# model_gbm <- gbm(train$forest_stock ~.,
#                 data = train,
#                 distribution = "gaussian",
#                 cv.folds = 10,
#                 shrinkage = .01,
#                 n.minobsinnode = 10,
#                 n.trees = 500)
# 
# pred_y <- predict.gbm(model_gbm, test_x)

```
